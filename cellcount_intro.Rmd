---
title: "Introduction to *cellcount* - Draft vignette"
author: "*T.E. Harman, M. Vandersea, K. Pokrzywinski*"
date: "04/19/2023"
abstract: >
  The *cellcount* package provides wrapper functions for  [*EBImage*](http://bioconductor.org/packages/devel/bioc/vignettes/EBImage/inst/doc/EBImage-introduction.html) to simplfy quantifying bacteria and cyanobacteria via flourescence microscopy. Cyanobacteria enumeration is an important tool to incorporate data results into mathematical models to assess bloom dynamics. However, standard manual cyanobacteria enumeration is considered time-consuming and can impact overall random error due to different inaccuracies from researcher to researcher. Here, we outline a new open-source tool, *cellcount*, a package designed for the computing language R to assist with cyanobacteria enumeration. Fluorescent microscopy images are analyzed by this package to generate cyanobacteria counts to assess overall cell density from samples.
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Getting started:

*cellcount* is an R package distributed freely by NOAA NCCOS HAB-F on [GitHub](https://github.com/orgs/HABF-SDI-NCCOS-NOAA/repositories) and uses components in the RStudio IDE program. Make sure to install both the latest version of R and RStudio.

To get started with *cellcount*, users can make a local clone of the repository using programs like [GitHub Desktop](https://desktop.github.com/) or similar programs. Users may also download the package from the provided release on GitHub that contains a zipped folder with the package material. Once cloned, open the R project file and install the package locally by selecting 'build' and 'install package', or use the shortcut Crtl+Shift+B (Cmd+Shift+B for MacOS users). You should now have the *cellcount* package installed. Use the following code to bring *cellcount* into the R environment:

```{r}
library(cellcount)
```

In addition, the following packages are required to use functions within *cellcount*:

- *EBImage*
- *tiff*
- *pixmap*
- *raster*
- *beepr*

*EBImage* uses the [Bioconductor](http://bioconductor.org) development software system while the remaining packages use the CRAN server built within R. Use the following code to install and load the packages into the R environment before starting: 

```{r, message=FALSE}
if (!require("EBImage")) {
  BiocManager::install("EBImage")
}
library(EBImage)

library(tiff)
library(pixmap)
library(raster)
library(beepr)
```

# Setting up directories/reading files:

Now that we have the basics installed, we can begin using the *cellcount* package. Start by generating a data frame for count data to be added into using the following code:

```{r}
Cell.Count <- data.frame(Image_File_Name = character(0), Cell_Count = numeric(0))
```

You'll need to generate a couple of directories; one for saving the unique
color label images and another for CSV files. In this example, we are using 
images *Microcystis* sp. cells. Please note that your 
directory addresses will be different. We recommend using a dedicated directory 
for *cellcount* results:

```{r,message=FALSE}
savdir <- ("C:/file path for saving CSV data")
image_savdir <- ("C:/file path for saving converted images")
```
```{r,include=FALSE}
savdir <- ("./inst/extdata/test_data/")
image_savdir <- ("./inst/extdata/test_results/")
```

Next, you'll need to read in the images you are interested in processing using
the following code. Once again, your directories will be different and must be
updated to the correct file address. However, in this example we will be using
the provided test images from this package:

```{r,message=FALSE}
images <- list.files("C:/file path of images to analyze", pattern = "tif", full.name = T)
images_names <- list.files("C:/file path of images to analyze", pattern = "tif", full.name = F)
```
```{r,include=FALSE}
images <- list.files("./inst/extdata/test_images/Microcystis_F192_40x/", pattern = "tif", full.name = T)
images_names <- list.files("./inst/extdata/test_images/Microcystis_F192_40x/", pattern = "tif", full.name = F)
```

In addition, you'll need to assign the file names to a vector along with adding
in characterization to each file for easy organization:

```{r}
file_name<-paste0("F192_")
```

Now we will "read" in the images that we are interested in analyzing. The
following code outlines this step using the "readTIFF" function from the 
*tiff* package. In addition, we'll need to re-orient the image as it's uploaded
into the environment. The "readTIFF" function uploads images in a portrait 
format - the "aperm" function reorients the uploaded image to a landscape format:

```{r, warning=FALSE}
imgNames <- paste0(file_name, images_names)
read_images <- lapply(images, readTIFF)
img_transposed <- lapply(read_images,aperm,c(2,1,3))
names(images) <- imgNames
```

# Beginning the conversion process:

Now that our images are within the R environment, we can begin to convert these
images into useful data that R can use to process images. First, we begin by
converting 24-bit images into 8-bit images using the "greyscale" function (see 
photo below). This function also has a built-in numerical contrast adjustment 
that end-users can adjust:

```{r,include=FALSE}
greyscale <- function(x, contrast = 2) {
  x <- contrast * x
  x <- x[, , 1] + x[, , 2] + x[, , 3]
  x <- x / max(x)
  x <- normalize(x, inputRange = c(0.1, 0.75))
  return(x)
}
```
```{r}
grey_images <- lapply(img_transposed, greyscale, contrast = 1)
display(grey_images[[5]])
```

Next, we will use the "mapped" function to turn the 8-bit image we just
converted into a data matrix. In addition, we use an additional function to 
determine the median intensity of each image. From this, users can add a numerical
buffer on top of the determined median intensity, giving a more accurate approach
to separating the background intensity from the intensity of cells within each
image:

```{r,include=FALSE}
mapped <- function(x, threshold = 0.3) {
  x <- as.matrix(x)
  x[x < threshold] <- 0
  return(x)
}
mapped_avg <- function(x) {
  x <- as.matrix(x)
  return(x)
}
```
```{r}
img1<-lapply(grey_images,mapped_avg)
pre_adj<-median(img1[[5]])
main_adj<-pre_adj+0.2
imagesMapped <- lapply(grey_images, mapped, threshold = main_adj)
```

Before we analyze our images in bulk, set aside some code space to visually 
analyze your images results. This could include adjusting the threshold
from the "mapped" function, the contrast from the "greyscale" function 
(if used), or could involve making adjustments to the "single_cell_convert" or
"filamentous_convert" functions, such as the width and height of the rectangular 
window, the pixel area threshold (i.e., removes cells or other objects under a 
certain pixel area),or the tolerance and 'ext' variables. Observe your initial 
results as indicated below and make adjustments where necessary:

```{r,include=FALSE}
border <- function(x, y) {
  c(x[1:y[1], 1], x[1:y[1], y[2]], x[1, 1:y[2]], x[y[1], 1:y[2]])
}
count_cells <- function(x) {
  countAll <- max(x)
  dims <- dim(x)
  border1 <- border(x, dims)
  ids <- unique(border1[which(border1 != 0)])
  countInner <- countAll - length(ids)
  return(countInner)
}
count_images <- function(image, normalize = TRUE, removeEdgeCells = TRUE) {
  if (removeEdgeCells) {
    dims <- dim(image)
    border1 <- border(image, dims)
    ids <- unique(border1[which(border1 != 0)])
    inner <- rmObjects(image, ids)
    EBImage::colorLabels(inner, normalize = normalize)
  } else {
    EBImage::colorLabels(image, normalize = normalize)
  }
}
single_cell_convert <- function(x, w = 17, h = 17, offset = 0.001, areathresh = 50, tolerance= 0.5, ext = 1) {
  image <- thresh(x, w = w, h = h, offset = offset)
  image1 <- fillHull(image)
  image2 <- watershed(distmap(image1), tolerance = tolerance, ext = ext)
  nf <- computeFeatures.shape(image2)
  nr <- which(nf[, "s.area"] < areathresh)
  image3 <- rmObjects(image2, nr)
  return(image3)
}
```
```{r}
imagesConverted <- single_cell_convert(imagesMapped[[5]], w = 10, h = 10, offset = 0.001, areathresh = 250, tolerance = 0.8, ext = 1)
final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
display(final_img)
```

# Analysis of images for producing count data:

Once you have made necessary adjustments, use the following for-loop to
analyze your images in bulk, one at a time. In this example using *Microcystis* sp.
images, the for-loop uses the "single_cell_convert" function to produce unique 
color labels on cells within an image and to produce a final image showcasing 
these labels using the "count_images" function. Finally, "count_cells" is used 
to count the number of unique color labels (i.e., cells). We also have 
integrated code to add these count results to the data frame made earlier, and 
also to save each unique color label image to the "image_savdir" directory:

```{r}
for (z in 1:length(images)) {
  imagesConverted <- single_cell_convert(imagesMapped[[z]], w = 10, h = 10, offset = 0.001, areathresh = 250, tolerance = 0.8, ext = 1)
  final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
  count <- count_cells(imagesConverted)
  Cell.Count[nrow(Cell.Count) + 1, ] <- c(imgNames[[z]], count)
  analyzed_image <- paste0(sub(".tif", replacement = "", x = imgNames[z]), "_analyzed.tiff")
  writeImage(final_img, files = paste0(image_savdir, analyzed_image),compression=c("LZW"))
}
```

Data from the image analysis has been generated in our data frame "Cell.Count"
that we previously made. We can use the following code to view our results:

```{r}
Cell.Count
```

Some images that were initially taken may be too poor of quality or contain
high background fluorescence, among other errors. The code below analyzes 
outliers from the produced data, within a range of two standard deviations 
above and below the median. The "outlier_detect" function tags which images are
out of this range and dictates a warning within our data frame, which is shown 
below. This alerts the end-user to perhaps re-image a particular sample, or
to investigate the error further.

```{r,include=FALSE}
outlier_detect<-function(){
  mean<-median(Cell.Count$Cell_Count)
  sd<-sd(Cell.Count$Cell_Count)*2
  sd_neg<-(mean-sd)
  sd_pos<-(mean+sd)
  SD_range_detection<-ifelse(sd_pos>Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)&
    ifelse(sd_neg<Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)
  return(SD_range_detection)
}
```
```{r}
Cell.Count$Cell_Count<-as.numeric(Cell.Count$Cell_Count)
Cell.Count$SD_range<-outlier_detect()
Cell.Count
```

In order to calculate cell density of these images, we can use the
"cell_density" function that's built into the *cellcount* package. We first
need to generate the total amount of cells counted from these images and
add it to our existing data frame using the following code:

```{r}
cell.total <- as.numeric(Cell.Count$Cell_Count)
cell.total <- sum(cell.total)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Total", cell.total,"null")
```

*Important note* - *the "null" data produced in the code above (and others that*
*follow) fills in the blanks from the previous data produced by the* 
*"outlier" function.*

Calculating cell density, taken from Wetzel and Likens 1991, requires multiple
values. End-users will need the following information to precisely 
calculate this value:

- Total counts (generated previously)
- Height of image field of view (μm)
- Width of image field of view (μm)
- Total number of images analyzed
- Filtration area (mm<sup>2</sup>)
- Volume filtered per image (mL)
- Total sample volume (mL)

Field of view (FOV - mm<sup>2</sup>) is an important variable calculated from image height and
image width. Image height and width are variables that are taken from dimensions 
disseminated by your microscope camera's manufacturer. Please refer to their 
documentation to calculate your FOV variable correctly.

With the variables calculated, the following code uses these variables to 
calculate cell density and adds the data into the "Cell.Count" data frame:

```{r,include=FALSE}
cell_density <- function(x, FOV = 0.0726, images = 10, filtration.area = 213.8, volume = 1, total.volume = 5) {
  MCF <- filtration.area / FOV
  N <- x / images
  cyano <- (MCF * N) / volume
  cyano_total <- cyano * total.volume
  return(cyano_total)
}
```
```{r}
cell.den <- cell_density(cell.total, FOV = 0.0726, images = 10, filtration.area = 213.8, volume = 1, total.volume = 5)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Density", cell.den,"null")
```

We can also calculate the average number of cells per image, as well as cells
per mL using the following code. Note that 'cell.av' must be divided by the
number of images the end-user has analyzed, and the 'cell.mL' must be divided
by the total volume from the original sample:

```{r}
cell.av<-(cell.total/10) #change this via total number of images
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Imaging Average",cell.av,"null")

cell.mL<-(cell.den/5) #change this via total volume
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Total Volume Cell per mL",cell.mL,"null")
```

We can now view our data frame to double check for any calculation errors:

```{r}
Cell.Count
```

Finally, we write the following code to export our finalized .csv file to our
pre-determined save directory:

```{r}
write.csv(Cell.Count, paste0(savdir, "/F192_Test counts.csv"))
```


# Output data from test images in the *cellcount* package:

### Test data results for *Microcystis* strain F-192
```{r,echo=FALSE}
display(final_img)
Cell.Count
```
<br>
<br>

```{r,include=FALSE}
# clear environment and free unused memory
rm(list=ls())
gc()
```

### Test data results for *Anabena* sp.
```{r,include=FALSE}
greyscale <- function(x, contrast = 2) {
  x <- contrast * x
  x <- x[, , 1] + x[, , 2] + x[, , 3]
  x <- x / max(x)
  x <- normalize(x, inputRange = c(0.1, 0.75))
  return(x)
}
mapped <- function(x, threshold = 0.3) {
  x <- as.matrix(x)
  x[x < threshold] <- 0
  return(x)
}
border <- function(x, y) {
  c(x[1:y[1], 1], x[1:y[1], y[2]], x[1, 1:y[2]], x[y[1], 1:y[2]])
}
count_cells <- function(x) {
  countAll <- max(x)
  dims <- dim(x)
  border1 <- border(x, dims)
  ids <- unique(border1[which(border1 != 0)])
  countInner <- countAll - length(ids)
  return(countInner)
}
count_images <- function(image, normalize = TRUE, removeEdgeCells = TRUE) {
  if (removeEdgeCells) {
    dims <- dim(image)
    border1 <- border(image, dims)
    ids <- unique(border1[which(border1 != 0)])
    inner <- rmObjects(image, ids)
    EBImage::colorLabels(inner, normalize = normalize)
  } else {
    EBImage::colorLabels(image, normalize = normalize)
  }
}
single_cell_convert <- function(x, w = 17, h = 17, offset = 0.001, areathresh = 50, tolerance= 0.5, ext = 1) {
  image <- thresh(x, w = w, h = h, offset = offset)
  image1 <- fillHull(image)
  image2 <- watershed(distmap(image1), tolerance = tolerance, ext = ext)
  nf <- computeFeatures.shape(image2)
  nr <- which(nf[, "s.area"] < areathresh)
  image3 <- rmObjects(image2, nr)
  return(image3)
}
filamentous_convert <- function(x, w = 17, h = 17, offset = 0.001, areathresh = 50, tolerance= 0.5, ext = 1) {
  image <- thresh(x, w = w, h = h, offset = offset)
  image1 <- watershed(distmap(image), tolerance = tolerance, ext = ext)
  image2 <- fillHull(image1)
  nf <- computeFeatures.shape(image2)
  nr <- which(nf[, "s.area"] < areathresh)
  image3 <- rmObjects(image2, nr)
  return(image3)
}
cell_density <- function(x, FOV = 0.0726, images = 10, filtration.area = 213.8, volume = 1, total.volume = 5) {
  MCF <- filtration.area / FOV
  N <- x / images
  cyano <- (MCF * N) / volume
  cyano_total <- cyano * total.volume
  return(cyano_total)
}
outlier_detect<-function(){
  mean<-median(Cell.Count$Cell_Count)
  sd<-sd(Cell.Count$Cell_Count)*2
  sd_neg<-(mean-sd)
  sd_pos<-(mean+sd)
  SD_range_detection<-ifelse(sd_pos>Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)&
    ifelse(sd_neg<Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)
  return(SD_range_detection)
}
```

```{r,echo=FALSE}
Cell.Count <- data.frame(Image_File_Name = character(0), Cell_Count = numeric(0))

file_name<-paste0("img_")

savdir <- ("./inst/extdata/test_data/")
image_savdir <- ("./inst/extdata/test_results/")
images <- list.files("./inst/extdata/test_images/NZ_Anabena_60x/", pattern = "tif", full.name = T)
images_names <- list.files("./inst/extdata/test_images/NZ_Anabena_60x/", pattern = "tif", full.name = F)

imgNames <- paste0(file_name, images_names)
read_images <- lapply(images, readTIFF)
img_transposed <- lapply(read_images,aperm,c(2,1,3))
names(images) <- imgNames

grey_images <- lapply(img_transposed, greyscale, contrast = 1)

mapped_avg <- function(x) {
  x <- as.matrix(x)
  return(x)
}
img1<-lapply(grey_images,mapped_avg)
pre_adj<-median(img1[[5]])
main_adj<-pre_adj+0.2
imagesMapped <- lapply(grey_images, mapped, threshold = main_adj)

imagesConverted <- filamentous_convert(imagesMapped[[5]], w = 10, h = 10, offset = 0.001, areathresh = 250, tolerance = 0.8, ext = 1)
final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
display(final_img)
```

```{r,echo=FALSE}
for (z in 1:length(images)) {
  adj1<-median(img1[[z]])
  adj2<-adj1+0.2
  imagesMapped <- lapply(grey_images, mapped, threshold = adj2)
  imagesConverted <- filamentous_convert(imagesMapped[[z]], w = 10, h = 10, offset = 0.001, areathresh = 250, tolerance = 0.8, ext = 1)
  final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
  count <- count_cells(imagesConverted)
  Cell.Count[nrow(Cell.Count) + 1, ] <- c(imgNames[[z]], count)
  analyzed_image <- paste0(sub(".tif", replacement = "", x = imgNames[z]), "_analyzed.tiff")
  writeImage(final_img, files = paste0(image_savdir, analyzed_image),compression=c("LZW"))
}

Cell.Count$Cell_Count<-as.numeric(Cell.Count$Cell_Count)
Cell.Count$SD_range<-outlier_detect()

cell.total <- as.numeric(Cell.Count$Cell_Count)
cell.total <- sum(cell.total)

Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Total", cell.total,"null")

cell.den <- cell_density(cell.total, FOV = 0.027770534, images = 10, filtration.area = 213.8, volume = 0.5, total.volume =15)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Density", cell.den,"null")

cell.av<-(cell.total/10)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Imaging Average",cell.av,"null")

cell.mL<-(cell.den/15)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Total Volume Cell per mL",cell.mL,"null")

write.csv(Cell.Count, paste0(savdir, "/Anabena_test counts.csv"))

Cell.Count
```
<br>
<br>

```{r,include=FALSE}
# clear environment and free unused memory
rm(list=ls())
gc()
```

### Test data results for *Shewanella* IRI-160
```{r,include=FALSE}
greyscale <- function(x, contrast = 2) {
  x <- contrast * x
  x <- x[, , 1] + x[, , 2] + x[, , 3]
  x <- x / max(x)
  x <- normalize(x, inputRange = c(0.1, 0.75))
  return(x)
}
mapped <- function(x, threshold = 0.3) {
  x <- as.matrix(x)
  x[x < threshold] <- 0
  return(x)
}
border <- function(x, y) {
  c(x[1:y[1], 1], x[1:y[1], y[2]], x[1, 1:y[2]], x[y[1], 1:y[2]])
}
count_cells <- function(x) {
  countAll <- max(x)
  dims <- dim(x)
  border1 <- border(x, dims)
  ids <- unique(border1[which(border1 != 0)])
  countInner <- countAll - length(ids)
  return(countInner)
}
count_images <- function(image, normalize = TRUE, removeEdgeCells = TRUE) {
  if (removeEdgeCells) {
    dims <- dim(image)
    border1 <- border(image, dims)
    ids <- unique(border1[which(border1 != 0)])
    inner <- rmObjects(image, ids)
    EBImage::colorLabels(inner, normalize = normalize)
  } else {
    EBImage::colorLabels(image, normalize = normalize)
  }
}
single_cell_convert <- function(x, w = 17, h = 17, offset = 0.001, areathresh = 50, tolerance= 0.5, ext = 1) {
  image <- thresh(x, w = w, h = h, offset = offset)
  image1 <- fillHull(image)
  image2 <- watershed(distmap(image1), tolerance = tolerance, ext = ext)
  nf <- computeFeatures.shape(image2)
  nr <- which(nf[, "s.area"] < areathresh)
  image3 <- rmObjects(image2, nr)
  return(image3)
}
filamentous_convert <- function(x, w = 17, h = 17, offset = 0.001, areathresh = 50, tolerance= 0.5, ext = 1) {
  image <- thresh(x, w = w, h = h, offset = offset)
  image1 <- watershed(distmap(image), tolerance = tolerance, ext = ext)
  image2 <- fillHull(image1)
  nf <- computeFeatures.shape(image2)
  nr <- which(nf[, "s.area"] < areathresh)
  image3 <- rmObjects(image2, nr)
  return(image3)
}
cell_density <- function(x, FOV = 0.0726, images = 10, filtration.area = 213.8, volume = 1, total.volume = 5) {
  MCF <- filtration.area / FOV
  N <- x / images
  cyano <- (MCF * N) / volume
  cyano_total <- cyano * total.volume
  return(cyano_total)
}
outlier_detect<-function(){
  mean<-median(Cell.Count$Cell_Count)
  sd<-sd(Cell.Count$Cell_Count)*2
  sd_neg<-(mean-sd)
  sd_pos<-(mean+sd)
  SD_range_detection<-ifelse(sd_pos>Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)&
    ifelse(sd_neg<Cell.Count$Cell_Count,Cell.Count$Cell_Count,NA)
  return(SD_range_detection)
}
```

```{r,echo=FALSE}
Cell.Count <- data.frame(Image_File_Name = character(0), Cell_Count = numeric(0))

file_name<-paste0("img_")

savdir <- ("./inst/extdata/test_data/")
image_savdir <- ("./inst/extdata/test_results/")
images <- list.files("./inst/extdata/test_images/Shewanella_100x_DAPI/", pattern = "tif", full.name = T)
images_names <- list.files("./inst/extdata/test_images/Shewanella_100x_DAPI/", pattern = "tif", full.name = F)

imgNames <- paste0(file_name, images_names)
read_images <- lapply(images, readTIFF)
img_transposed <- lapply(read_images,aperm,c(2,1,3))
names(images) <- imgNames

grey_images <- lapply(img_transposed, greyscale, contrast = 1)

mapped_avg <- function(x) {
  x <- as.matrix(x)
  return(x)
}
img1<-lapply(grey_images,mapped_avg)
pre_adj<-median(img1[[5]])
main_adj<-pre_adj+0.2
imagesMapped <- lapply(grey_images, mapped, threshold = main_adj)

imagesConverted <- single_cell_convert(imagesMapped[[5]], w = 10, h = 10, offset = 0.001, areathresh = 50, tolerance = 0.8, ext = 1)
final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
display(final_img)
```

```{r,echo=FALSE}
for (z in 1:length(images)) {
  adj1<-median(img1[[z]])
  adj2<-adj1+0.2
  imagesMapped <- lapply(grey_images, mapped, threshold = adj2)
  imagesConverted <- single_cell_convert(imagesMapped[[z]], w = 10, h = 10, offset = 0.001, areathresh = 50, tolerance = 0.8, ext = 1)
  final_img <- count_images(imagesConverted, normalize = T, removeEdgeCells = T)
  count <- count_cells(imagesConverted)
  Cell.Count[nrow(Cell.Count) + 1, ] <- c(imgNames[[z]], count)
  analyzed_image <- paste0(sub(".tif", replacement = "", x = imgNames[z]), "_analyzed.tiff")
  writeImage(final_img, files = paste0(image_savdir, analyzed_image),compression=c("LZW"))
}

Cell.Count$Cell_Count<-as.numeric(Cell.Count$Cell_Count)
Cell.Count$SD_range<-outlier_detect()

cell.total <- as.numeric(Cell.Count$Cell_Count)
cell.total <- sum(cell.total)

Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Total", cell.total,"null")

cell.den <- cell_density(cell.total, FOV = 0.00042, images = 10, filtration.area = 213.8, volume = 0.02, total.volume =2)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Cell Density", cell.den,"null")

cell.av<-(cell.total/10)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Imaging Average",cell.av,"null")

cell.mL<-(cell.den/2)
Cell.Count[nrow(Cell.Count) + 1, ] <- c("Total Volume Cell per mL",cell.mL,"null")

write.csv(Cell.Count, paste0(savdir, "/Shewanella_test counts.csv"))

Cell.Count
```


# Shiny app user-interface for ***cellcount*** analysis:

Several informal discussions with researchers have expressed interest in a easy-to-use analysis interface for inexperienced R users
to utilize the ***cellcount*** tool. The following overview uses ***Shiny*** apps to enter input data and run image analyses. 

### Inputting data
The *input_data_GUI* function generates a Shiny UI where users enter information regarding directories, numerical and categorical data, 
and selecting analysis type. Tabs to the left of the UI separate particular categories for easy organization. Once all data has been
provided, users complete the input of data by selecting the "Completion" tab and clicking the "Submit data entries" button to export 
data to the local R environment.

![Visual demonstration of the Shiny GUI for inputting data.](C:/Users/Tyler.Harman/Pictures/cellcount-UI_1.png)

### Running the image analysis

*analyze_images_GUI* is a simple UI that contains three interactive buttons as well as a data table below. "Run Image Analysis" simply runs the image analysis previously outlined in this document and uses the inputted data from the *input_data_GUI* function. Once the completion sound has been played (using the *beepr* package), users can click the "Refresh" button to update the table below with the analyzed data and review. Once finished with analysis, the "Close window" button to exit the UI.

![Visual demonstration of the Shiny GUI for running image analysis.](C:/Users/Tyler.Harman/Pictures/cellcount-UI_2.png)


# Package limitations:

The current version of this package may be limiting for some users regarding processing power. Analysis with this package uses local memory, which may be limiting if expected to analyze large amounts of images in batches. We recommend at least 16GB of localized RAM, the use of a cloud computing supercomputer (i.e. Microsoft Azure), or organize images in easier-to-analyze batches to reduce local memory strain.

Users must be aware that this package does not contain abilities to identify distinct cells. The development of this package utilized carefully cultured monoculture of various cyanobacteria species. Users may find difficulty in using this analysis tool if cultures contain heavy amounts of particulates, other cellular debris, and contamination of other species. It is advised to use this tool for single-species only, however future developments of this tool are planned include identifying cell features and building image libraries of specific cellular species for use in environmental samples.

Outside of package limitations, users must be aware of limitations that may arise from poor microscopy imaging; reduce lighting as much as possible, avoid heavy background fluorescence, reduce debris/particulates, and so forth. Good images produce good *cellcount* results - keep this in mind as you utilize this tool.

# Literature cited:

Wetzel, RG and Likens, GE. 1991. Limnological Analyses, Second Edition. Springer-
Verlag. 391 pp.

Pau, G, Fuchs, F, Sklyar, O, Boutros, M, Huber, W. 2010. EBImage—an R package for image processing with applications to cellular phenotypes, Bioinformatics, 26(7): 979–981, https://doi.org/10.1093/bioinformatics/btq046

Pokrzywinski, K, Boyd, B, Smith, J. 2019. A High-throughput Method for Counting 
Cyanobacteria Using Fluorescence Microscopy. ERDC TR-19-21.